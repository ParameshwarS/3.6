1. If 7TB is the available disk space per node (9 disks with 1 TB, 2 disk for operating system etc.
were excluded.). Assuming initial data size is 600 TB. How will you estimate the number of data
nodes (n)?

Let the number of data nodes be n.
    The data to be stored in hdfs be d. 
    The disk space available for each node be Ds.

For d=600TB   Ds=7TB,
The number of nodes required will be 600/7=85.7142,
which is 86.
 
So, 86 data nodes are needed.

2.Imagine that you are uploading a file of 500MB into HDFS.100MB of data is successfully
uploaded into HDFS and another client wants to read the uploaded data while the upload is still in
progress. What will happen in such a scenario, will the 100 MB of data that is uploaded will it be
displayed?

Let us assume that block size will be 100mb.
Since the first 100mb will be in the 1st block and,
The next data will be stored in another block, The data can be accessed(Displayed).

If The data transfer into the 1st block is still in process,then it has to be completed before client can access it.

